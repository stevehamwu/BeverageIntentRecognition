#!/usr/bin/env python3
"""
BeverageIntentRecognition - Complete System
LLM-based intent classification for all beverage scenarios with comprehensive evaluation
"""

import json
import requests
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Any, Tuple
from collections import defaultdict, Counter


class IntentType(Enum):
    """Complete intent types for beverage understanding"""
    GRAB_DRINK = "grab_drink"
    DELIVER_DRINK = "deliver_drink"
    RECOMMEND_DRINK = "recommend_drink"
    CANCEL_ORDER = "cancel_order"
    QUERY_STATUS = "query_status"
    MODIFY_ORDER = "modify_order"


@dataclass
class IntentResult:
    """Result of intent analysis"""
    intent: IntentType
    confidence: float
    entities: Dict[str, Any]
    raw_text: str


class LLMIntentUnderstanding:
    """Simple LLM-based intent understanding system"""
    
    def __init__(self, api_base: str = "http://10.109.214.243:8000/v1", api_key: str = "EMPTY"):
        self.api_base = api_base
        self.api_key = api_key
        self.model_id = "Qwen3-8B"
    
    def few_shot_examples(self) -> List[Dict[str, str]]:
        """Comprehensive few-shot examples for all 6 intent types"""
        return [
            # Grab drink examples
            {
                "input": "ç»™æˆ‘æ¥ä¸€æ¯æ‹¿é“",
                "output": json.dumps({
                    "intent": "grab_drink",
                    "confidence": 0.9,
                    "entities": {"drink_name": "æ‹¿é“"}
                }, ensure_ascii=False)
            },
            {
                "input": "æ¥æ¯å¤§æ¯å†°ç¾å¼",
                "output": json.dumps({
                    "intent": "grab_drink", 
                    "confidence": 0.95,
                    "entities": {"drink_name": "ç¾å¼", "size": "å¤§æ¯", "temperature": "å†°"}
                }, ensure_ascii=False)
            },
            {
                "input": "è¦ä¸¤ç“¶å¯å£å¯ä¹",
                "output": json.dumps({
                    "intent": "grab_drink",
                    "confidence": 0.92,
                    "entities": {"drink_name": "å¯ä¹", "brand": "å¯å£å¯ä¹", "quantity": 2}
                }, ensure_ascii=False)
            },
            # Deliver drink examples
            {
                "input": "æŠŠè¿™æ¯å’–å•¡é€åˆ°ä¼šè®®å®¤",
                "output": json.dumps({
                    "intent": "deliver_drink",
                    "confidence": 0.9,
                    "entities": {"drink_name": "å’–å•¡", "location": "ä¼šè®®å®¤"}
                }, ensure_ascii=False)
            },
            {
                "input": "éº»çƒ¦æŠŠçƒ­èŒ¶é€åˆ°åŠå…¬å®¤",
                "output": json.dumps({
                    "intent": "deliver_drink",
                    "confidence": 0.88,
                    "entities": {"drink_name": "èŒ¶", "temperature": "çƒ­", "location": "åŠå…¬å®¤"}
                }, ensure_ascii=False)
            },
            # Recommend drink examples
            {
                "input": "æ¨èç‚¹æç¥çš„é¥®æ–™",
                "output": json.dumps({
                    "intent": "recommend_drink",
                    "confidence": 0.9,
                    "entities": {"preference": "æç¥"}
                }, ensure_ascii=False)
            },
            {
                "input": "æœ‰ä»€ä¹ˆæ¸…çˆ½çš„é¥®å“å—",
                "output": json.dumps({
                    "intent": "recommend_drink",
                    "confidence": 0.85,
                    "entities": {"preference": "æ¸…çˆ½"}
                }, ensure_ascii=False)
            },
            {
                "input": "å»ºè®®ä¸ªè§£è…»çš„èŒ¶ç±»",
                "output": json.dumps({
                    "intent": "recommend_drink",
                    "confidence": 0.87,
                    "entities": {"preference": "è§£è…»", "drink_name": "èŒ¶"}
                }, ensure_ascii=False)
            },
            # Cancel order examples
            {
                "input": "ç®—äº†ï¼Œä¸è¦äº†",
                "output": json.dumps({
                    "intent": "cancel_order",
                    "confidence": 0.95,
                    "entities": {}
                }, ensure_ascii=False)
            },
            {
                "input": "å–æ¶ˆåˆšæ‰çš„å’–å•¡è®¢å•",
                "output": json.dumps({
                    "intent": "cancel_order",
                    "confidence": 0.9,
                    "entities": {"drink_name": "å’–å•¡"}
                }, ensure_ascii=False)
            },
            # Query status examples
            {
                "input": "æˆ‘çš„é¥®æ–™å¥½äº†å—",
                "output": json.dumps({
                    "intent": "query_status",
                    "confidence": 0.92,
                    "entities": {}
                }, ensure_ascii=False)
            },
            {
                "input": "æ‹¿é“åšå¥½äº†æ²¡æœ‰",
                "output": json.dumps({
                    "intent": "query_status",
                    "confidence": 0.88,
                    "entities": {"drink_name": "æ‹¿é“"}
                }, ensure_ascii=False)
            },
            # Modify order examples
            {
                "input": "æ”¹æˆå¤§æ¯çš„",
                "output": json.dumps({
                    "intent": "modify_order",
                    "confidence": 0.9,
                    "entities": {"size": "å¤§æ¯"}
                }, ensure_ascii=False)
            },
            {
                "input": "æ¢æˆçƒ­çš„å¥¶èŒ¶å§",
                "output": json.dumps({
                    "intent": "modify_order",
                    "confidence": 0.85,
                    "entities": {"temperature": "çƒ­", "drink_name": "å¥¶èŒ¶"}
                }, ensure_ascii=False)
            }
        ]
    
    def create_prompt(self, user_input: str) -> str:
        """Create prompt with few-shot examples"""
        examples_text = ""
        for example in self.few_shot_examples():
            examples_text += f"è¾“å…¥: {example['input']}\nè¾“å‡º: {example['output']}\n\n"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé¥®æ–™æ„å›¾ç†è§£ç³»ç»Ÿã€‚åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«æ„å›¾ç±»å‹å¹¶æå–å®ä½“ä¿¡æ¯ã€‚

æ”¯æŒçš„æ„å›¾ç±»å‹:
- grab_drink: æŠ“å–/è·å–é¥®æ–™çš„è¯·æ±‚
- deliver_drink: é€’é€é¥®æ–™åˆ°æŒ‡å®šä½ç½®
- recommend_drink: é¥®æ–™æ¨èè¯·æ±‚
- cancel_order: å–æ¶ˆè®¢å•è¯·æ±‚
- query_status: æŸ¥è¯¢é¥®æ–™çŠ¶æ€
- modify_order: ä¿®æ”¹è®¢å•å†…å®¹

å®ä½“ç±»å‹:
- drink_name: é¥®æ–™åç§°ï¼ˆå’–å•¡ã€èŒ¶ã€å¯ä¹ç­‰ï¼‰
- brand: å“ç‰Œä¿¡æ¯ï¼ˆå¯å£å¯ä¹ã€é›ªç¢§ç­‰ï¼‰
- size: è§„æ ¼å¤§å°ï¼ˆå¤§æ¯ã€ä¸­æ¯ã€å°æ¯ã€ç“¶è£…ï¼‰
- temperature: æ¸©åº¦è¦æ±‚ï¼ˆçƒ­ã€æ¸©ã€å†°ã€å¸¸æ¸©ï¼‰
- quantity: æ•°é‡
- location: ä½ç½®ä¿¡æ¯
- preference: åå¥½éœ€æ±‚ï¼ˆæç¥ã€è§£è…»ã€æ¸…çˆ½ã€æš–èƒƒç­‰ï¼‰

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«intentã€confidence(0-1)ã€entitieså­—æ®µã€‚

ç¤ºä¾‹:
{examples_text}
ç°åœ¨åˆ†æè¿™ä¸ªè¾“å…¥:
è¾“å…¥: {user_input}
è¾“å‡º:"""
        
        return prompt
    
    def understand_intent(self, user_input: str) -> IntentResult:
        """Main intent understanding method"""
        prompt = self.create_prompt(user_input)
        
        payload = {
            "model": self.model_id,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1,
            "max_tokens": 200,
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{self.api_base}/chat/completions",
                headers={"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"},
                json=payload,
                timeout=30
            )
            
            if response.status_code != 200:
                return self._fallback_analysis(user_input, f"API error: {response.status_code}")
            
            response_data = response.json()
            raw_text = response_data["choices"][0]["message"]["content"].strip()
            
            # Parse JSON response
            try:
                result_data = json.loads(raw_text)
                intent = IntentType(result_data["intent"])
                confidence = float(result_data["confidence"])
                entities = result_data.get("entities", {})
                
                return IntentResult(
                    intent=intent,
                    confidence=confidence,
                    entities=entities,
                    raw_text=raw_text
                )
            except (json.JSONDecodeError, KeyError, ValueError) as e:
                return self._fallback_analysis(user_input, raw_text)
                
        except requests.RequestException as e:
            return self._fallback_analysis(user_input, f"Request failed: {str(e)}")
    
    def _fallback_analysis(self, user_input: str, error_info: str) -> IntentResult:
        """Enhanced rule-based fallback for all 6 intent types"""
        entities = {}
        
        # Intent classification keywords
        deliver_keywords = ["é€", "é€’é€", "é€åˆ°", "é€ç»™", "æ‹¿ç»™"]
        recommend_keywords = ["æ¨è", "å»ºè®®", "ä»€ä¹ˆ", "æœ‰æ²¡æœ‰", "æ¸…çˆ½", "æç¥", "æš–èƒƒ", "è§£è…»"]
        cancel_keywords = ["å–æ¶ˆ", "ç®—äº†", "ä¸è¦äº†", "æ’¤é”€", "ä¸è¦"]
        query_keywords = ["å¥½äº†å—", "åšå¥½äº†", "å®Œæˆäº†", "çŠ¶æ€", "è¿›åº¦", "æ€ä¹ˆæ ·äº†"]
        modify_keywords = ["æ”¹æˆ", "æ¢æˆ", "ä¿®æ”¹", "æ”¹ä¸º", "å˜æˆ"]
        
        # Determine intent
        if any(keyword in user_input for keyword in deliver_keywords):
            intent = IntentType.DELIVER_DRINK
        elif any(keyword in user_input for keyword in recommend_keywords):
            intent = IntentType.RECOMMEND_DRINK
        elif any(keyword in user_input for keyword in cancel_keywords):
            intent = IntentType.CANCEL_ORDER
        elif any(keyword in user_input for keyword in query_keywords):
            intent = IntentType.QUERY_STATUS
        elif any(keyword in user_input for keyword in modify_keywords):
            intent = IntentType.MODIFY_ORDER
        else:
            intent = IntentType.GRAB_DRINK
        
        # Entity extraction
        # Drink names
        drinks = ["æ‹¿é“", "ç¾å¼", "å’–å•¡", "èŒ¶", "å¥¶èŒ¶", "å¯ä¹", "é›ªç¢§", "æ©™æ±"]
        for drink in drinks:
            if drink in user_input:
                entities["drink_name"] = drink
                break
        
        # Brands
        brands = ["å¯å£å¯ä¹", "é›ªç¢§", "ç™¾äº‹", "æ˜Ÿå·´å…‹"]
        for brand in brands:
            if brand in user_input:
                entities["brand"] = brand
                break
        
        # Sizes
        sizes = ["å¤§æ¯", "ä¸­æ¯", "å°æ¯", "è¶…å¤§æ¯", "ç“¶è£…"]
        for size in sizes:
            if size in user_input:
                entities["size"] = size
                break
        
        # Temperature
        temperatures = ["çƒ­", "å†°", "æ¸©", "å¸¸æ¸©"]
        for temp in temperatures:
            if temp in user_input:
                entities["temperature"] = temp
                break
        
        # Preferences
        preferences = ["æç¥", "æ¸…çˆ½", "æš–èƒƒ", "è§£è…»"]
        for pref in preferences:
            if pref in user_input:
                entities["preference"] = pref
                break
        
        # Location
        locations = ["ä¼šè®®å®¤", "åŠå…¬å®¤", "å‰å°", "ä¼‘æ¯å®¤"]
        for loc in locations:
            if loc in user_input:
                entities["location"] = loc
                break
        
        # Quantity (simple number extraction)
        import re
        quantity_match = re.search(r'(\d+)[æ¯ç“¶ä¸ªä»½]', user_input)
        if quantity_match:
            entities["quantity"] = int(quantity_match.group(1))
        elif "ä¸¤" in user_input:
            entities["quantity"] = 2
        elif "ä¸‰" in user_input:
            entities["quantity"] = 3
        
        return IntentResult(
            intent=intent,
            confidence=0.6,  # Lower confidence for fallback
            entities=entities,
            raw_text=f"Fallback analysis: {error_info}"
        )


def create_test_cases() -> List[Dict[str, Any]]:
    """Create comprehensive test dataset with 15 cases as per README specs"""
    return [
        # Grab drink tests (3 cases)
        {
            "input": "ç»™æˆ‘æ¥ä¸€æ¯çƒ­æ‹¿é“",
            "expected_intent": "grab_drink",
            "expected_entities": {"drink_name": "æ‹¿é“", "temperature": "çƒ­"}
        },
        {
            "input": "æ¥æ¯å¤§æ¯å†°ç¾å¼",
            "expected_intent": "grab_drink", 
            "expected_entities": {"drink_name": "ç¾å¼", "size": "å¤§æ¯", "temperature": "å†°"}
        },
        {
            "input": "è¦ä¸¤ç“¶å¯å£å¯ä¹",
            "expected_intent": "grab_drink",
            "expected_entities": {"drink_name": "å¯ä¹", "brand": "å¯å£å¯ä¹", "quantity": 2}
        },
        
        # Deliver drink tests (2 cases)
        {
            "input": "æŠŠè¿™æ¯å’–å•¡é€åˆ°ä¼šè®®å®¤",
            "expected_intent": "deliver_drink",
            "expected_entities": {"drink_name": "å’–å•¡", "location": "ä¼šè®®å®¤"}
        },
        {
            "input": "éº»çƒ¦æŠŠçƒ­èŒ¶é€åˆ°åŠå…¬å®¤",
            "expected_intent": "deliver_drink",
            "expected_entities": {"drink_name": "èŒ¶", "temperature": "çƒ­", "location": "åŠå…¬å®¤"}
        },
        
        # Recommend drink tests (4 cases)
        {
            "input": "æ¨èç‚¹æç¥çš„é¥®æ–™",
            "expected_intent": "recommend_drink",
            "expected_entities": {"preference": "æç¥"}
        },
        {
            "input": "æœ‰ä»€ä¹ˆæ¸…çˆ½çš„é¥®å“å—",
            "expected_intent": "recommend_drink",
            "expected_entities": {"preference": "æ¸…çˆ½"}
        },
        {
            "input": "å»ºè®®ä¸ªè§£è…»çš„èŒ¶ç±»",
            "expected_intent": "recommend_drink",
            "expected_entities": {"preference": "è§£è…»", "drink_name": "èŒ¶"}
        },
        {
            "input": "ä»€ä¹ˆé¥®æ–™æ¯”è¾ƒæš–èƒƒ",
            "expected_intent": "recommend_drink",
            "expected_entities": {"preference": "æš–èƒƒ"}
        },
        
        # Cancel order tests (2 cases)
        {
            "input": "ç®—äº†ï¼Œä¸è¦äº†",
            "expected_intent": "cancel_order",
            "expected_entities": {}
        },
        {
            "input": "å–æ¶ˆåˆšæ‰çš„å’–å•¡è®¢å•",
            "expected_intent": "cancel_order",
            "expected_entities": {"drink_name": "å’–å•¡"}
        },
        
        # Query status tests (2 cases)
        {
            "input": "æˆ‘çš„é¥®æ–™å¥½äº†å—",
            "expected_intent": "query_status",
            "expected_entities": {}
        },
        {
            "input": "æ‹¿é“åšå¥½äº†æ²¡æœ‰",
            "expected_intent": "query_status",
            "expected_entities": {"drink_name": "æ‹¿é“"}
        },
        
        # Modify order tests (2 cases)
        {
            "input": "æ”¹æˆå¤§æ¯çš„",
            "expected_intent": "modify_order",
            "expected_entities": {"size": "å¤§æ¯"}
        },
        {
            "input": "æ¢æˆçƒ­çš„å¥¶èŒ¶å§",
            "expected_intent": "modify_order",
            "expected_entities": {"temperature": "çƒ­", "drink_name": "å¥¶èŒ¶"}
        }
    ]


def calculate_metrics(y_true: List[str], y_pred: List[str]) -> Dict[str, Any]:
    """Calculate precision, recall, F1 for each class and overall"""
    from collections import defaultdict
    
    # Get unique labels
    labels = sorted(set(y_true + y_pred))
    
    # Calculate per-class metrics
    metrics = {}
    confusion_matrix = defaultdict(lambda: defaultdict(int))
    
    # Build confusion matrix
    for true_label, pred_label in zip(y_true, y_pred):
        confusion_matrix[true_label][pred_label] += 1
    
    # Calculate precision, recall, F1 for each class
    class_metrics = {}
    for label in labels:
        tp = confusion_matrix[label][label]  # True positives
        fp = sum(confusion_matrix[other_label][label] for other_label in labels if other_label != label)  # False positives
        fn = sum(confusion_matrix[label][other_label] for other_label in labels if other_label != label)  # False negatives
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        class_metrics[label] = {
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "support": tp + fn
        }
    
    # Calculate macro averages
    macro_precision = sum(m["precision"] for m in class_metrics.values()) / len(class_metrics)
    macro_recall = sum(m["recall"] for m in class_metrics.values()) / len(class_metrics)
    macro_f1 = sum(m["f1"] for m in class_metrics.values()) / len(class_metrics)
    
    # Calculate micro averages
    total_tp = sum(confusion_matrix[label][label] for label in labels)
    total_fp = sum(confusion_matrix[pred][true] for true in labels for pred in labels if pred != true)
    total_fn = total_fp  # In multi-class, FP for one class = FN for others
    
    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0
    
    return {
        "class_metrics": class_metrics,
        "macro_precision": macro_precision,
        "macro_recall": macro_recall,
        "macro_f1": macro_f1,
        "micro_precision": micro_precision,
        "micro_recall": micro_recall,
        "micro_f1": micro_f1,
        "confusion_matrix": dict(confusion_matrix),
        "accuracy": sum(1 for t, p in zip(y_true, y_pred) if t == p) / len(y_true)
    }


def evaluate_system(intent_system: LLMIntentUnderstanding) -> Dict[str, Any]:
    """Comprehensive system evaluation with precision/recall/F1"""
    test_cases = create_test_cases()
    total_tests = len(test_cases)
    
    results = []
    y_true_intent = []
    y_pred_intent = []
    entity_matches = []
    
    print("=== å¼€å§‹å…¨é¢è¯„ä¼° ===\n")
    
    for i, test_case in enumerate(test_cases, 1):
        user_input = test_case["input"]
        expected_intent = test_case["expected_intent"]
        expected_entities = test_case["expected_entities"]
        
        result = intent_system.understand_intent(user_input)
        
        # Store for metrics calculation
        y_true_intent.append(expected_intent)
        y_pred_intent.append(result.intent.value)
        
        # Check intent accuracy
        intent_match = result.intent.value == expected_intent
        
        # Check entity accuracy (all expected entities must be present and correct)
        entity_match = True
        for key, expected_value in expected_entities.items():
            if key not in result.entities or result.entities[key] != expected_value:
                entity_match = False
                break
        
        # Also check no extra critical entities (flexible approach)
        entity_matches.append(entity_match)
        
        results.append({
            "input": user_input,
            "expected_intent": expected_intent,
            "predicted_intent": result.intent.value,
            "intent_correct": intent_match,
            "expected_entities": expected_entities,
            "predicted_entities": result.entities,
            "entity_correct": entity_match,
            "confidence": result.confidence
        })
        
        print(f"æµ‹è¯• {i}: {user_input}")
        print(f"  æ„å›¾: {expected_intent} -> {result.intent.value} {'âœ“' if intent_match else 'âœ—'}")
        print(f"  å®ä½“: {expected_entities} -> {result.entities} {'âœ“' if entity_match else 'âœ—'}")
        print(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print()
    
    # Calculate intent classification metrics
    intent_metrics = calculate_metrics(y_true_intent, y_pred_intent)
    
    # Calculate entity extraction accuracy
    entity_accuracy = sum(entity_matches) / len(entity_matches) * 100
    
    # Print comprehensive results
    print("=== è¯¦ç»†è¯„ä¼°æŠ¥å‘Š ===")
    print(f"æ€»æµ‹è¯•ç”¨ä¾‹: {total_tests}")
    print()
    
    print("ğŸ“Š æ„å›¾åˆ†ç±»æŒ‡æ ‡:")
    print(f"  å‡†ç¡®ç‡ (Accuracy): {intent_metrics['accuracy']:.2%}")
    print(f"  å®å¹³å‡ - ç²¾ç¡®ç‡: {intent_metrics['macro_precision']:.2%}, å¬å›ç‡: {intent_metrics['macro_recall']:.2%}, F1: {intent_metrics['macro_f1']:.2%}")
    print(f"  å¾®å¹³å‡ - ç²¾ç¡®ç‡: {intent_metrics['micro_precision']:.2%}, å¬å›ç‡: {intent_metrics['micro_recall']:.2%}, F1: {intent_metrics['micro_f1']:.2%}")
    print()
    
    print("ğŸ“‹ å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
    for intent_type, metrics in intent_metrics['class_metrics'].items():
        print(f"  {intent_type}:")
        print(f"    ç²¾ç¡®ç‡: {metrics['precision']:.2%}, å¬å›ç‡: {metrics['recall']:.2%}, F1: {metrics['f1']:.2%}")
        print(f"    æ”¯æŒæ ·æœ¬æ•°: {metrics['support']}")
    print()
    
    print("ğŸ¯ å®ä½“æŠ½å–æŒ‡æ ‡:")
    print(f"  å®ä½“æŠ½å–å‡†ç¡®ç‡: {entity_accuracy:.2f}%")
    print()
    
    print("ğŸ“ˆ æ··æ·†çŸ©é˜µ:")
    all_intents = sorted(set(y_true_intent + y_pred_intent))
    print("çœŸå®\\é¢„æµ‹", end="")
    for intent in all_intents:
        print(f"\t{intent[:8]}", end="")
    print()
    
    for true_intent in all_intents:
        print(f"{true_intent[:8]}", end="")
        for pred_intent in all_intents:
            count = intent_metrics['confusion_matrix'].get(true_intent, {}).get(pred_intent, 0)
            print(f"\t{count}", end="")
        print()
    print()
    
    print("âœ… ç›®æ ‡è¾¾æˆæƒ…å†µ:")
    intent_acc_pct = intent_metrics['accuracy'] * 100
    print(f"  æ„å›¾è¯†åˆ«å‡†ç¡®ç‡: {intent_acc_pct:.2f}% (ç›®æ ‡: â‰¥80%) {'âœ“' if intent_acc_pct >= 80 else 'âœ—'}")
    print(f"  å®ä½“æŠ½å–å‡†ç¡®ç‡: {entity_accuracy:.2f}% (ç›®æ ‡: â‰¥75%) {'âœ“' if entity_accuracy >= 75 else 'âœ—'}")
    print(f"  å®å¹³å‡F1åˆ†æ•°: {intent_metrics['macro_f1']:.2%}")
    
    return {
        "intent_metrics": intent_metrics,
        "entity_accuracy": entity_accuracy,
        "detailed_results": results,
        "total_cases": total_tests
    }


def test_llm_connection(intent_system: LLMIntentUnderstanding) -> bool:
    """Test if LLM API is accessible"""
    try:
        response = requests.get(f"{intent_system.api_base}/models", timeout=5)
        return response.status_code == 200
    except:
        return False


def main():
    """Main function - Complete system demo"""
    print("ğŸš€ é¥®æ–™æ„å›¾è¯†åˆ«ç³»ç»Ÿ - å®Œæ•´ç‰ˆ")
    print("Complete System with Advanced Evaluation\n")
    
    # Initialize system
    intent_system = LLMIntentUnderstanding()
    
    # Test LLM connection
    if test_llm_connection(intent_system):
        print("âœ“ LLMæœåŠ¡è¿æ¥æ­£å¸¸")
    else:
        print("âš  LLMæœåŠ¡è¿æ¥å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½è§„åˆ™åŒ¹é…ä½œä¸ºåå¤‡æ–¹æ¡ˆ")
    
    print()
    
    # Run comprehensive evaluation
    evaluation_results = evaluate_system(intent_system)
    
    # Quick demo examples for all intent types
    print("\n=== å…¨åŠŸèƒ½æ¼”ç¤º ===")
    demo_inputs = [
        "ç»™æˆ‘æ¥æ¯å¤§æ¯çƒ­æ‹¿é“",           # grab_drink
        "æŠŠå’–å•¡é€åˆ°ä¼šè®®å®¤",            # deliver_drink  
        "æ¨èä¸ªæç¥çš„é¥®æ–™",            # recommend_drink
        "ç®—äº†ï¼Œä¸è¦äº†",               # cancel_order
        "æˆ‘çš„å¥¶èŒ¶å¥½äº†å—",             # query_status
        "æ”¹æˆå†°çš„"                   # modify_order
    ]
    
    for demo_input in demo_inputs:
        result = intent_system.understand_intent(demo_input)
        print(f"è¾“å…¥: {demo_input}")
        print(f"  -> æ„å›¾: {result.intent.value}, ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print(f"  -> å®ä½“: {result.entities}")
        print()
    
    # Summary
    intent_acc = evaluation_results['intent_metrics']['accuracy'] * 100
    entity_acc = evaluation_results['entity_accuracy']
    macro_f1 = evaluation_results['intent_metrics']['macro_f1'] * 100
    
    print("="*50)
    print("ğŸ¯ ç³»ç»Ÿæ€§èƒ½æ€»ç»“")
    print(f"   æ„å›¾è¯†åˆ«å‡†ç¡®ç‡: {intent_acc:.1f}%")
    print(f"   å®ä½“æŠ½å–å‡†ç¡®ç‡: {entity_acc:.1f}%") 
    print(f"   å®å¹³å‡F1åˆ†æ•°: {macro_f1:.1f}%")
    print(f"   æ”¯æŒæ„å›¾ç±»å‹: 6ç§å®Œæ•´åœºæ™¯")
    print(f"   æ”¯æŒå®ä½“ç±»å‹: 7ç§å®Œæ•´ä¿¡æ¯")
    print("="*50)


if __name__ == "__main__":
    main()